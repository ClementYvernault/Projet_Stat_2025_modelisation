---
title: "PIGAL - Analyse PLS multiblocs suivie d'une classification k-means des variables respiratoires"
author: 
    -name : "Christelle FABLET"
    -name : "Antoni Guàrdia Sanz"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
  theme: "architect"
highlight: github
number_sections: TRUE
editor_options: 
  markdown: 
    wrap: 72
---

```{=html}
<style type="text/css">
  body{
    font-size: 5pt;
  }
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Packages**

```{r error=FALSE, message=FALSE, warning=FALSE}
# chargement des packages nécessaires pour la suite
library(fastDummies)
library(ade4)
library(factoextra)
library(cluster)
library(knitr)
library(table1)
library(FactoMineR)
library(dplyr)
library(writexl)
library(adegraphics)

```


```{r, echo = T, warning = F, message = F, eval = T, include = F}
rm(list=ls())
setwd("/home/rogerbernat/Documents/Projet_Stat_2025_modelisation")
```

**Charger les données**

```{r, echo = T, warning = F, message = F, eval = T, include = F}

donnees <- readRDS("data_post_etape_4_Forest.Rdata")

```

## \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

#Analyse multiblocs - 21 variables X et une variable Y

## \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

data.clean = fichier contenant 21 variables X et une variable Y.


```{r, echo = T, warning = F, message = F, eval = T, include = F}
set.seed(1234567)

# suppression variable code elevage
data.clean <- donnees[-1]
colnames(data.clean)
rownames(data.clean) <- donnees$code_elevage
noms.ligne <- donnees$code_elevage
```

*Etape 1* 

On réalise le découpage par les blocs en accord avec le fichier variables_Sujet_22_envoi.xlsx

```{r, echo = T, warning = F, message = F}
X01_Logement_Entretien <- data.clean[, c("X22x1_LOC_INF_rec", "X07x1_AN_CONST4_mean_3", "ENG_TROU", "T13_ENG_milieuDegrad.x")]
X02_Alimentation <- data.clean[, c("T10_PS_EauDebi_3", "T10_PS_AlimPoNourrLongpPo", "X09x3_FAB_CROISS_reg_rec")]
X03_Gestion_Maladies <- data.clean[, c("X18x2_ABBTX_PS", "X19x2_ABB_E")]
X04_Biosecurite <- data.clean[, c("X12x2_MAT_PC", "X12x2_MAT1FRLAV_1", "T16_BS_TenueSpeciElev", "X13x2_QUAI_t")]
X05_Facteurs_Infectieux <- data.clean[, c("A03_Pos10sVERS", "A03_PosSeroMyAs", "A03_TxPosSero22sTgReel", "A04_My10Mfloc", "A05_TxPos10sGRIPPEReel")]
X06_Caracteristiques_Generales <- data.clean[, c("X06x1_gene_majo_1_rec", "X25x1_ElvAlterChoiPers", "LR_LRF")]
```

*Etape 2*

Création des dummy (ie binaires) variables avec le package fastDummies. La variable prise en référence correspond à celle dont l'effectif de réponse est le plus élevé.

```{r, echo = T, warning = F, message = F}

data <- list(X01_Logement_Entretien, X02_Alimentation, X03_Gestion_Maladies, X04_Biosecurite, X05_Facteurs_Infectieux, X06_Caracteristiques_Generales)

for(i in 1:length(data)){
  df <- data[[i]]
  for(var in names(df)){
    if(is.factor(df[[var]])){
      df <- dummy_cols(df, var, remove_selected_columns = TRUE, remove_most_frequent_dummy = TRUE)
    }
  }
  data[[i]] <- df
}
```

*Etape 3* 
La variable Y est en 3 modalités donc elle est également recodée en dummy variables selon le code indiqué ci-dessous.
Introduction de la variable Y codée en 3 dummy (ie transformation de Y en 3 variables binaires) variables :

```{r, echo = T, warning = F, message = F}
dummy_y <- data.frame(y = data.clean$y)

# Create des 3 Y
dummy_y$sain <- as.integer(dummy_y$y == "Sain")
dummy_y$ps_malade <- as.integer(dummy_y$y == "PS_malade")
dummy_y$eng_malade <- as.integer(dummy_y$y == "ENG_malade")

#suppression de y, la variable Y initiale, qui a été récodée en 3 niveaux Y
dummy_y <- dummy_y[,-1] 
summary(dummy_y) 
# Vérifions que la moyenne vaut bien 1 
sum(unlist(lapply(dummy_y, mean))) == 1
```

*Etape 4* 
Création d'un bloc pour la variable Y codée en dummy variables.

```{r}
# on ne prendra pas le plus fréquent ie eng_malade
summary(dummy_y)

#création d'un vecteur Y
bloc.Y <- dummy_y[,1:2]

data[[7]] <- bloc.Y
```

*Etape 5* 

Renommer les blocs:

```{r, echo = T, warning = F, message = F}

new_names <- c("X01_Logement_Entretien", "X02_Alimentation", "X03_Gestion_Maladies", "X04_Biosecurite", "X05_Facteurs_Infectieux", "X06_Caracteristiques_Generales", "Bloc_Y")
names(data) <- new_names
```

*Etape 6* 

**PASSAGE à l'analyse mbPLS**

## Préparation des données

```{r, echo = T, warning = F, message = F}
Y <- data[[7]]

row.names(Y)<-rownames(data[[1]])
#renommer les lignes du nouveau Y par les numéros des data 1 à 7 car Y prend le code elevage (PIGAL/ELEV/01...) alors que les autres fichiers ont un numéro d'ordre (perte du code_elevage); sans cela le code d'après bloque #à voir si cette étape est nécessaire dans votre code selon la configuration de votre fichier.
dudiY.ergo <- dudi.pca(Y, center = TRUE, scale = TRUE, scannf = FALSE)
ktabX.ergo <- ktab.list.df(data[1:6])
```
## Variabilité cumulé Y 
```{r}
var_expl <- dudiY.ergo$eig / sum(dudiY.ergo$eig) * 100
var_expl
```

## mbPLS

```{r, echo = T, warning = F, message = F}
res.mbpls2   <- mbpls(dudiY.ergo, ktabX.ergo, scale = T, option = "uniform", scannf = FALSE, nf = 10)
res.plot     <- plot(res.mbpls2)


res.2foldcv2 <- testdim(res.mbpls2, nrepet = 500)  # calcul long
res.2foldcv2
```
## Variance expliquée par bloc


```{R}

# Remplacer les NaN par NA pour éviter les erreurs
rmsec_values <- res.2foldcv2$statsRMSEc$Mean
rmsec_values[is.nan(rmsec_values)] <- NA

# Définir les limites de l'axe Y pour inclure les deux courbes
ylim_range <- range(c(res.2foldcv2$statsRMSEv$Mean, rmsec_values), na.rm = TRUE)

# Tracer la courbe d'erreur de validation (rouge)
plot(1:23, res.2foldcv2$statsRMSEv$Mean, type = "b", pch = 16, col = "red",
     xlab = "Nombre de dimensions", ylab = "Erreur (RMSE)", ylim = ylim_range,
     main = "Validation croisée 2-fold (Erreur en fonction des dimensions)")

# Ajouter la courbe d'erreur d'apprentissage (bleue)
lines(1:23, rmsec_values, type = "b", pch = 16, col = "blue")

# Ajouter la légende
legend("topright", legend = c("Erreur validation", "Erreur apprentissage"),
       col = c("red", "blue"), pch = 16, lty = 1)
```

NB : les variables X sont centrées et réduites à ce niveau


# Récupération des composantes de tous les axes pour réaliser une classification k-means à partir de ces composantes

```{r, echo = T, warning = F, message = F}
#pour les X
recup_compos_X<-res.mbpls2$lX
#pour les Y
recup_compos_Y<-res.mbpls2$lY
summary(recup_compos_X)
```


# Approche mbPLS combinée à une classification k-means

L’objectif de cette approche est de regarder si de l’hétérogénéité existe au sein des niveaux de Y et que cela s’explique par des pratiques associées qui sont différentes.

## Sélection des axes 

```{r}
par(mfrow = c(2, 3))
# Def qqc couleurs 
red<-rgb(1,0,0,0.5)
orange <- rgb(1, 0.5, 0, 0.5)  
green <- rgb(0, 0.8, 0, 0.5)
# Boucle for
for(name in names(summary(res.mbpls2))[-1]){
    var.cum <- summary(res.mbpls2)[[name]][,2]
    color <- ifelse(var.cum <= 25, red, ifelse(var.cum < 30, orange, green))
    barplot(var.cum,
            main=name,
            col = color,
            cex.main=2.25,
            cex.axis=3.5,
            ylim= c(0,87))
}
# legend("topright", legend = c("Erreur validation", "Erreur apprentissage"), col = c("red", "blue"), pch = 16, lty = 1)
par(mfrow = c(1, 2))
var.cum <- summary(res.mbpls2)$YandX[,2]
color <- ifelse(var.cum <= 25, red, ifelse(var.cum < 30, orange, green))

barplot(var.cum,
            main="Y",
            col = color,
            cex.main=2.75,
            cex.axis=3.5,
            ylim= c(0,100))
var.cum <- summary(res.mbpls2)$YandX[,4]
color <- ifelse(var.cum <= 25, red, ifelse(var.cum < 30, orange, green))

barplot(var.cum,
            main="X",
            col = color,
            cex.main=2.75,
            cex.axis=3.5,
            ylim= c(0,100))


```
Afin d'avoir une variabilité cumulé pour la partie des variables X d'au moins de 25-30%, il faudrait garder 3 axes. 
## K-means
```{r}
selection_dimensions <- function(res.mbpls, n_dim){
  #composantes du bloc X
  data_clust <- res.mbpls[,c(1:n_dim)] #x premières composantes récupérées pour la suite de la classification
  data_clust.scaled <- scale(data_clust) # centrer

  #calculate gap statistic based on number of clusters
  gap_stat <- clusGap(data_clust.scaled,
                      FUN = kmeans,
                      nstart = 25,
                      K.max = 12,
                      B = 150)

  #plot number of clusters vs. gap statistic
  return(fviz_gap_stat(gap_stat))
}

selection_dimensions(recup_compos_X, 3)
```
Il semblerait que 3 ou 6 clusters semblent ce dégager.
### Analyse 3 clusters
```{R}
analyse_clusters <- function(res.mbpls, donnees, n_dim, centers){
  data_clust <- res.mbpls[,c(1:n_dim)] #x premières composantes récupérées pour la suite de la classification
  data_clust.scaled <- scale(data_clust) # centrer


  #perform k-means clustering with k = x clusters (x=centers)
  res.km <- kmeans(data_clust.scaled, centers = centers, nstart = 25)


  #plot results of final k-means model
  resultat.2dim <- fviz_cluster(res.km, data = data_clust.scaled,
              geom = "point",
              ellipse.type = "convex", 
              ggtheme = theme_bw()
              )

  data.avec_cl <- cbind(donnees, res.km$cluster)
  nom.clust <- paste0("cluster_km", n_dim)
  names(data.avec_cl) <- c(names(donnees), nom.clust)

  data.avec_clb <-data_frame(data.avec_cl)

  #déclarer la variable cluster_km en facteur
  data.avec_clb[[nom.clust]] <- as.factor(data.avec_clb[[nom.clust]])

  data.table <- kable(table1(as.formula(paste("~ . |", nom.clust)), data = data.avec_clb))

  data.dsc <- catdes(data.avec_clb, num.var = ncol(data.avec_clb), proba =0.05)$category

  

  cluster_list <- list()
  for (i in 1:centers) {
    cluster_list[[paste("cluster", i, sep = "_")]] <- as.data.frame(data.dsc[[as.character(i)]])
    cluster_list[[paste("cluster", i, sep = "_")]] <- dplyr::as_data_frame(cluster_list[[paste("cluster", i, sep = "_")]], rownames = "Variable")
  }
  file_path <- paste0("mb-pls/Clusters_km", paste0(n_dim, ".xlsx"))
  write_xlsx(cluster_list, file_path, col_names = TRUE, format_headers = TRUE, use_zip64 = FALSE)
  
  return(list("res.km"=res.km,
               "plot.km"=resultat.2dim,
               "res.table"=data.table,
               "res.catdes"=data.dsc))

}
res.3.3 <- analyse_clusters(recup_compos_X, data.clean, 3, 3)
res.3.3
```
# TODO
### Analyse 6 clusters
```{r}
par(mfrow = c(1, 1))

res.3.6 <- analyse_clusters(recup_compos_X, data.clean, 3, 6)
res.3.6
```
# TODO
## Hdbscan
```{r}
claasif.hdbscan <- function(res.mbpls, n_dim) {
  # Extract the first n_dim components from the res.mbpls object
  data_clust <- res.mbpls[, c(1:n_dim)]
  data_clust.scaled <- scale(data_clust)  # Scale the data

  # Apply HDBSCAN clustering
  hdbscan_result <- hdbscan(data_clust.scaled, minPts = 5)  # minPts is a key parameter for HDBSCAN

  # Visualize the clustering results
  plot(data_clust.scaled, col = hdbscan_result$cluster + 1, pch = 20, main = "HDBSCAN Clustering")
  legend("topright", legend = unique(hdbscan_result$cluster), col = unique(hdbscan_result$cluster + 1), pch = 20)

  # Return the HDBSCAN result for further inspection
  return(hdbscan_result)
}
res.hdb <- claasif.hdbscan(recup_compos_X, 3)
res.hdb
```
Pour des clusters avec au moins 5 individus, on obtient 3 cluster comme dans kmeans. Cependant, 54 élevages ne sont pas classées, on n'utilisera donc pas cette méthode par manque de généralisation.


# Estimation du poids des blocs et des variables dans l'explication de Y et sélection de variables

* Utilitzar fitxer nou fitxer profe titol com el de la secció *


Par l’autre approche mbPLS où vous allez supprimer pas à pas les variables non significatives dans l’explication de Y, vous identifierez des variables qui jouent en moyenne sur chaque niveau et pas le type de subtilité observé en conservant toute les variables du modèle du départ combiné à une classification k-means.