#vide 
rm(list=ls())

# installation des packages
install.packages("VGAM")
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list=ls())

# chargement des donn√©es 
donnees_forest <- readRDS("Projet_Stat_2025_modelisation/data_post_etape_4_Forest.Rdata", "rb")
donnees_mean <- readRDS("Projet_Stat_2025_modelisation/data_post_etape_4_Mean.Rdata", "rb")

```
=======
Blocs_Y_76X01_X07
>>>>>>> 793ef1d9fec51ef1276e9d9f0e638ab56804269f
# on commence par travailler avec donnees_forest
colnames(donnees_forest)
library(caret)
set.seed(36)
train_index <- createDataPartition(donnees_forest$y, p = 0.8, list = FALSE)

# Diviser les donn√©es en train et test
```{r}
donnees_forest2 <- donnees_forest[,-1]
train_data <- donnees_forest[train_index, ]
train_data <- train_data[,-1]
test_data <- donnees_forest[-train_index, ]
```

# V√©rifier les proportions dans les deux ensembles
prop.table(table(train_data$y))
prop.table(table(test_data$y))


On s'interesse aux probl√®mes de s√©paration parfaite.
Il n'y a pas de probl√®me pour les variables cat√©gorielles car on a d√©j√† v√©rfi√© les proportions.
```{r}
# S√©lectionner uniquement les variables explicatives
vars_explicatives <- names(donnees_forest)[!names(donnees_forest) %in% "y"]

# Boucle pour v√©rifier la s√©paration parfaite
for (var in vars_explicatives) {
  tab <- table(donnees_forest$y, donnees_forest[[var]])
  
  # V√©rifie si une modalit√© d'une variable pr√©dit toujours une seule classe de y
  if (any(rowSums(tab == 0) == (nrow(tab) - 1))) {
    cat("‚ö†Ô∏è Probl√®me de s√©paration parfaite d√©tect√© pour :", var, "\n")
    print(tab)
  }
}
```

On regarde donc chaque variables num√©rique en effectuant une regression multinomiale.
Pour A04_My10Mfloc, il y a un probl√®me de fitted_prob pour:
Individu 33 :
ENG_malade: 0.1156
PS_malade: 0.0245
Sain: 0.8599

Individu 98 :
ENG_malade: 0.0378
PS_malade: 0.0042
Sain: 0.9581
Il faut donc supprimer l'individu ou la variable. Una valeur trop √©lev√© -> sain

```{r}
library(VGAM)  # Pour la r√©gression multinomiale

# S√©lectionner uniquement les variables quantitatives
vars_quanti <- names(donnees_forest)[sapply(donnees_forest, is.numeric)]

for (var in vars_quanti) {
  cat("\nüîπ Test de la variable :", var, "\n")
  
  # Mod√®le de r√©gression multinomiale
  formula <- as.formula(paste("y ~", var))
  model <- vglm(formula, family = multinomial, data = donnees_forest)

  # Extraire les coefficients
  coef_val <- coef(model)
  
  # V√©rifier si certains coefficients sont tr√®s grands (seuil arbitraire)
  if (any(abs(coef_val) > 10)) {
    cat("‚ö†Ô∏è Alerte : Probl√®me de s√©paration possible ! Coefficients √©lev√©s pour", var, "\n")
  }

  # V√©rifier les fitted probabilities
  fitted_probs <- fitted(model)
  if (any(fitted_probs < 0.01 | fitted_probs > 0.99)) {
    cat("‚ö†Ô∏è Alerte : Probl√®me de fitted probabilities proches de 0 ou 1 pour", var, "\n")
    print(fitted_probs)
  }
}

```

On va recoder la variable en 3 modalit√©s 
```{r}
library(ggplot2)

# Afficher la distribution sous forme de table pour voir les valeurs distinctes
table(donnees_forest$A04_My10Mfloc)

# Affichage graphique
ggplot(donnees_forest, aes(x = as.factor(A04_My10Mfloc))) +
  geom_bar(fill = "steelblue", color = "black") +
  theme_minimal() +
  labs(title = "Distribution de A04_My10Mfloc (discr√®te)")

# Trier les valeurs distinctes et leurs effectifs
effectifs <- as.data.frame(table(donnees_forest$A04_My10Mfloc))
colnames(effectifs) <- c("valeur", "effectif")
effectifs$valeur <- as.numeric(as.character(effectifs$valeur))  # Conversion en num√©rique si besoin
effectifs <- effectifs[order(effectifs$valeur), ]

# Trouver un seuil pour avoir au moins 15% d'effectif dans la derni√®re modalit√©
total_effectif <- sum(effectifs$effectif)
effectifs$cumule <- cumsum(effectifs$effectif) / total_effectif  # Fr√©quence cumul√©e

# D√©terminer le seuil pour "√©lev√©" (valeur o√π on d√©passe 85% des observations)
seuil_eleve <- min(effectifs$valeur[effectifs$cumule >= 0.85])

# D√©finition des 3 groupes en fonction de cette coupure
donnees_forest$A04_My10Mfloc <- cut(
  donnees_forest$A04_My10Mfloc,
  breaks = c(-Inf, 0, seuil_eleve, Inf),
  labels = c("zero", "moyen", "√©lev√©")
)

# Transformer en facteur
donnees_forest$A04_My10Mfloc <- as.factor(donnees_forest$A04_My10Mfloc)

# V√©rification de la r√©partition des classes
table(donnees_forest$A04_My10Mfloc)
prop.table(table(donnees_forest$A04_My10Mfloc))

# Affichage graphique apr√®s transformation
ggplot(donnees_forest, aes(x = A04_My10Mfloc)) +
  geom_bar(fill = "darkorange", color = "black") +
  theme_minimal() +
  labs(title = "Distribution de A04_My10Mfloc apr√®s transformation en factor : seuil = 43839")

```

```{r}
set.seed(36)
train_index <- createDataPartition(donnees_forest$y, p = 0.8, list = FALSE)
train_data <- donnees_forest[train_index, ]
test_data <- donnees_forest[-train_index, ]

library("VGAM")
multinomial_logistic_model <- vglm(y ~ . ,data = train_data, family = multinomial)
```
# analyse
```{r}

summary(multinomial_logistic_model)
```
```{r}
# Charger la librairie dplyr si ce n'est pas d√©j√† fait
library(dplyr)

# Supprimer les variables sp√©cifiques de la base de donn√©es
donnees_forest <- donnees_forest %>%
  select(-"X07x1_AN_CONST4_mean_3", 
         -"T16_BS_TenueSpeciElev", 
         -"LR_LRF", 
         -"T10_PS_AlimPoNourrLongpPo")

# V√©rifier les nouvelles colonnes de la base de donn√©es
colnames(donnees_forest)

set.seed(36)
train_index <- createDataPartition(donnees_forest$y, p = 0.8, list = FALSE)
train_data <- donnees_forest[train_index, ]
test_data <- donnees_forest[-train_index, ]

library("VGAM")
multinomial_logistic_model <- vglm(y ~ . ,data = train_data, family = multinomial)
```

```{r}
model_summary <- summary(multinomial_logistic_model)
coefficients <- coefficients(model_summary)

# Utiliser la m√©thode 'z' pour obtenir les valeurs des statistiques de Wald
wald_statistics <- coefficients[, "z value"]

# Utiliser la m√©thode 'Pr(>|z|)' pour obtenir les p-values
p_values <- coefficients[, "Pr(>|z|)"]

# V√©rifier les p-values
print(p_values)

# Identifier les variables avec des p-values significatives (par exemple p < 0.05)
significant_vars <- names(p_values)[p_values < 0.05]

# Cr√©er une formule avec les variables significatives
formula <- as.formula(paste("y ~", paste(significant_vars, collapse = " + ")))
formula
# Cr√©er un nouveau mod√®le avec les variables significatives
significant_model <- vglm("y ~ X22x1_LOC_INF_rec1:2 + X12x2_MAT_PC2:1 + X12x2_MAT_PC2:2 + 
    T10_PS_EauDebi_31:1 + X13x2_QUAI_t1:2 + X18x2_ABBTX_PS1:1 + 
    X19x2_ABB_E1:2 + A03_PosSeroMyAsOui:2 + A03_TxPosSero22sTgReel:1", data = train_data, family = multinomial())

# Afficher le r√©sum√© du nouveau mod√®le
summary(significant_model)
```


